# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ytv0Qt177YIDNH6ZPIcth7NA45QvHmZo
"""

# -*- coding: utf-8 -*-
"""Driver Drowsiness Detection Final Project"""

import requests
from IPython.display import Image
import numpy as np
import pandas as pd
import os
import cv2
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelBinarizer
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
import opendatasets as od
from sklearn.metrics import classification_report, confusion_matrix
from google.colab.patches import cv2_imshow

# Download Dataset from Kaggle
od.download("https://www.kaggle.com/datasets/dheerajperumandla/drowsiness-dataset")
od.download('https://www.kaggle.com/datasets/adinishad/prediction-images')

# Defining the Image Size and Categories
IMG_SIZE = 145
categories = ["yawn", "no_yawn", "Closed", "Open"]

# Haar Cascade for face detection
face_cascade = cv2.CascadeClassifier('./prediction-images/haarcascade_frontalface_default.xml')

# Function to preprocess and resize images
def process_image(directory, categories, face_cascade):
    data = []
    for category in categories:
        path = os.path.join(directory, category)
        class_num = categories.index(category)
        for img in os.listdir(path):
            try:
                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)
                faces = face_cascade.detectMultiScale(img_array, 1.3, 5)
                for (x, y, w, h) in faces:
                    roi_color = img_array[y:y + h, x:x + w]
                    resized_image = cv2.resize(roi_color, (IMG_SIZE, IMG_SIZE))
                    data.append([resized_image, class_num])
            except Exception as e:
                print(f"Error processing image {img}: {e}")
    return data

# Processing images
data = process_image('./drowsiness-dataset/train', categories, face_cascade)

# Preparing features and labels
X = []
y = []
for feature, label in data:
    X.append(feature)
    y.append(label)

X = np.array(X)
X = X.reshape(-1, IMG_SIZE, IMG_SIZE, 3)

# One-Hot Encoding of labels
label_bin = LabelBinarizer()
y = label_bin.fit_transform(y)
y = np.array(y)

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)

# Data Augmentation
train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.2, horizontal_flip=True, rotation_range=30)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow(X_train, y_train, shuffle=True)
test_generator = test_datagen.flow(X_test, y_test, shuffle=True)

# Building the CNN Model
model = Sequential()
model.add(Conv2D(512, (3, 3), activation="relu", input_shape=X_train.shape[1:]))
model.add(MaxPooling2D(2, 2))
model.add(Conv2D(512, (3, 3), activation="relu"))
model.add(MaxPooling2D(2, 2))
model.add(Conv2D(256, (3, 3), activation="relu"))
model.add(MaxPooling2D(2, 2))
model.add(Conv2D(256, (3, 3), activation="relu"))
model.add(MaxPooling2D(2, 2))
model.add(Conv2D(256, (3, 3), activation="relu"))
model.add(MaxPooling2D(2, 2))

# Flatten and Dense layers
model.add(Flatten())
model.add(Dropout(0.5))
model.add(Dense(128, activation="relu"))
model.add(Dense(64, activation="relu"))
model.add(Dense(4, activation="softmax"))

# Compile Model
model.compile(loss="categorical_crossentropy", metrics=["accuracy"], optimizer="adam")
model.summary()

# Training the Model
history = model.fit(train_generator, epochs=50, validation_data=test_generator)

# Save the model
model.save("drowsiness_model.h5")

# Evaluate the Model
test_loss, test_accuracy = model.evaluate(test_generator)
print(f'Test Loss: {test_loss}')
print(f'Test Accuracy: {test_accuracy}')

# Classification Report and Confusion Matrix
# Classification Report and Confusion Matrix
from sklearn.utils.multiclass import unique_labels

# Classification Report and Confusion Matrix
predictions = model.predict(X_test)
predicted_classes = np.argmax(predictions, axis=1)

print(classification_report(np.argmax(y_test, axis=1), predicted_classes, target_names=categories))

cm = confusion_matrix(np.argmax(y_test, axis=1), predicted_classes)
print("Confusion Matrix:\n", cm)



# Function to prepare and predict new images
def prepare(filepath):
    img_array = cv2.imread(filepath, cv2.IMREAD_COLOR)
    img_array = img_array / 255.0  # Normalize image
    resized_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))
    return resized_array.reshape(-1, IMG_SIZE, IMG_SIZE, 3)

# Testing with custom image input
def predict_image(image_path):
    prediction = model.predict([prepare(image_path)])
    prediction_label = np.argmax(prediction)
    print(f"Prediction Label: {prediction_label}")
    print(f"Prediction: {categories[prediction_label]}")

# Example Usage: Predict on a random image
predict_image("./drowsiness-dataset/train/Closed/_34.jpg")

# Visualize the model
from keras.utils.vis_utils import plot_model
plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)

import visualkeras
visualkeras.layered_view(model, legend=True, draw_volume=False)

import os
import numpy as np
import cv2
from tensorflow.keras.utils import to_categorical, load_img, img_to_array
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import opendatasets as od
from sklearn.metrics import classification_report, confusion_matrix
from google.colab.patches import cv2_imshow

# Download Dataset from Kaggle
od.download("https://www.kaggle.com/datasets/dheerajperumandla/drowsiness-dataset")
od.download('https://www.kaggle.com/datasets/adinishad/prediction-images')
# تنظیمات اولیه
IMG_SIZE = 145
BATCH_SIZE = 32
EPOCHS = 20
LEARNING_RATE = 0.0001
CATEGORIES = ["yawn", "no_yawn", "Closed", "Open"]

# پردازش تصاویر
def process_image(directory, categories, img_size):
    data = []
    for category in categories:
        path = os.path.join(directory, category)
        class_num = categories.index(category)
        for img in os.listdir(path):
            try:
                img_path = os.path.join(path, img)
                img = load_img(img_path, target_size=(img_size, img_size))
                img_array = img_to_array(img) / 255.0  # نرمال‌سازی تصاویر
                data.append([img_array, class_num])
            except Exception as e:
                print(f"Error processing image {img_path}: {e}")
    return data

# بارگذاری داده‌ها
train_dir = './drowsiness-dataset/train'
data = process_image(train_dir, CATEGORIES, IMG_SIZE)

# آماده‌سازی ویژگی‌ها و برچسب‌ها
X, y = [], []
for feature, label in data:
    X.append(feature)
    y.append(label)

X = np.array(X, dtype='float32')
y = np.array(y)
y = to_categorical(y, num_classes=len(CATEGORIES))

# تقسیم داده‌ها
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# تولید داده‌های افزوده‌شده
train_datagen = ImageDataGenerator(
    zoom_range=0.2,
    horizontal_flip=True,
    rotation_range=30,
    width_shift_range=0.1,
    height_shift_range=0.1
)
test_datagen = ImageDataGenerator()

train_generator = train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)
test_generator = test_datagen.flow(X_test, y_test, batch_size=BATCH_SIZE)

# استفاده از MobileNetV2 به عنوان مدل از پیش‌آموزش‌دیده
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))
base_model.trainable = False  # فریز کردن لایه‌های از پیش آموزش‌دیده

# افزودن لایه‌های بالایی
model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dropout(0.5),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(len(CATEGORIES), activation='softmax')
])

# کامپایل مدل
optimizer = Adam(learning_rate=LEARNING_RATE)
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

# آموزش مدل
history = model.fit(train_generator, epochs=EPOCHS, validation_data=test_generator)

# ارزیابی مدل
test_loss, test_accuracy = model.evaluate(test_generator)
print(f"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}")

# پیش‌بینی و گزارش عملکرد
y_pred = np.argmax(model.predict(X_test), axis=1)
y_true = np.argmax(y_test, axis=1)
print(classification_report(y_true, y_pred, target_names=CATEGORIES))

# نمایش ماتریس درهم‌ریختگی
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8, 6))
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
plt.xticks(np.arange(len(CATEGORIES)), CATEGORIES, rotation=45)
plt.yticks(np.arange(len(CATEGORIES)), CATEGORIES)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# رسم نمودار دقت و خطا
def plot_history(history):
    plt.figure(figsize=(12, 4))

    # دقت
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.title('Model Accuracy')

    # خطا
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.title('Model Loss')

    plt.show()

plot_history(history)

import os
import numpy as np
import cv2
from tensorflow.keras.utils import to_categorical, load_img, img_to_array
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import opendatasets as od

# Download Dataset from Kaggle
od.download("https://www.kaggle.com/datasets/dheerajperumandla/drowsiness-dataset")

# تنظیمات اولیه
IMG_SIZE = 145
BATCH_SIZE = 32
EPOCHS = 20
LEARNING_RATE = 0.0001
CATEGORIES = ["yawn", "no_yawn", "Closed", "Open"]

# بهبود پیش‌پردازش تصویر
def preprocess_image(image_path, img_size):
    try:
        img = cv2.imread(image_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        # فیلتر گوسی برای کاهش نویز
        img = cv2.GaussianBlur(img, (5, 5), 0)

        # افزایش کنتراست با CLAHE
        lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)
        l, a, b = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        l = clahe.apply(l)
        lab = cv2.merge((l, a, b))
        img = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)

        # تغییر سایز تصویر و نرمال‌سازی
        img = cv2.resize(img, (img_size, img_size))
        img = img / 255.0
        return img
    except Exception as e:
        print(f"Error processing image {image_path}: {e}")
        return None

# پردازش تصاویر
def process_image(directory, categories, img_size):
    data = []
    for category in categories:
        path = os.path.join(directory, category)
        class_num = categories.index(category)
        for img_name in os.listdir(path):
            img_path = os.path.join(path, img_name)
            img = preprocess_image(img_path, img_size)
            if img is not None:
                data.append([img, class_num])
    return data

# بارگذاری داده‌ها
train_dir = './drowsiness-dataset/train'
data = process_image(train_dir, CATEGORIES, IMG_SIZE)

# آماده‌سازی ویژگی‌ها و برچسب‌ها
X, y = zip(*data)
X = np.array(X, dtype='float32')
y = to_categorical(np.array(y), num_classes=len(CATEGORIES))

# تقسیم داده‌ها
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# تولید داده‌های افزوده‌شده
train_datagen = ImageDataGenerator(
    zoom_range=0.2,
    horizontal_flip=True,
    rotation_range=30,
    width_shift_range=0.1,
    height_shift_range=0.1
)
test_datagen = ImageDataGenerator()

train_generator = train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)
test_generator = test_datagen.flow(X_test, y_test, batch_size=BATCH_SIZE)

# استفاده از MobileNetV2 به عنوان مدل از پیش‌آموزش‌دیده
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))
base_model.trainable = False

# افزودن لایه‌های بالایی
model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dropout(0.5),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(len(CATEGORIES), activation='softmax')
])

# کامپایل مدل
optimizer = Adam(learning_rate=LEARNING_RATE)
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

# آموزش مدل
history = model.fit(train_generator, epochs=EPOCHS, validation_data=test_generator)

# ارزیابی مدل
test_loss, test_accuracy = model.evaluate(test_generator)
print(f"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}")

# پیش‌بینی و گزارش عملکرد
y_pred = np.argmax(model.predict(X_test), axis=1)
y_true = np.argmax(y_test, axis=1)
print(classification_report(y_true, y_pred, target_names=CATEGORIES))

# نمایش ماتریس درهم‌ریختگی
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8, 6))
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
plt.xticks(np.arange(len(CATEGORIES)), CATEGORIES, rotation=45)
plt.yticks(np.arange(len(CATEGORIES)), CATEGORIES)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# رسم نمودار دقت و خطا
def plot_history(history):
    plt.figure(figsize=(12, 4))

    # دقت
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.title('Model Accuracy')

    # خطا
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.title('Model Loss')

    plt.show()

plot_history(history)

import os
import numpy as np
import cv2
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import opendatasets as od

# Download Dataset from Kaggle
od.download("https://www.kaggle.com/datasets/dheerajperumandla/drowsiness-dataset")

# تنظیمات اولیه
IMG_SIZE = 145
BATCH_SIZE = 32
EPOCHS = 20
LEARNING_RATE = 0.0001
CATEGORIES = ["yawn", "no_yawn", "Closed", "Open"]

# پیش‌پردازش تصویر
def preprocess_image(img_path, img_size):
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)  # تبدیل به YCbCr
    img[:, :, 0] = cv2.equalizeHist(img[:, :, 0])  # افزایش کنتراست کانال روشنایی
    img = cv2.cvtColor(img, cv2.COLOR_YCrCb2BGR)  # بازگشت به RGB
    img = cv2.resize(img, (img_size, img_size))  # تغییر اندازه
    img = img / 255.0  # نرمال‌سازی
    return img

# پردازش تصاویر با پیش‌پردازش
def process_image_with_preprocessing(directory, categories, img_size):
    data = []
    for category in categories:
        path = os.path.join(directory, category)
        class_num = categories.index(category)
        for img_name in os.listdir(path):
            try:
                img_path = os.path.join(path, img_name)
                img = preprocess_image(img_path, img_size)
                data.append([img, class_num])
            except Exception as e:
                print(f"Error processing image {img_path}: {e}")
    return data

# بارگذاری داده‌ها
train_dir = './drowsiness-dataset/train'
data = process_image_with_preprocessing(train_dir, CATEGORIES, IMG_SIZE)

# آماده‌سازی ویژگی‌ها و برچسب‌ها
X, y = zip(*data)
X = np.array(X, dtype='float32')
y = np.array(y)
y = to_categorical(y, num_classes=len(CATEGORIES))

# تقسیم داده‌ها
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# تقویت داده‌ها
train_datagen = ImageDataGenerator(
    zoom_range=0.3,
    horizontal_flip=True,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    brightness_range=[0.8, 1.2]
)
test_datagen = ImageDataGenerator()

train_generator = train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)
test_generator = test_datagen.flow(X_test, y_test, batch_size=BATCH_SIZE)

# استفاده از MobileNetV2 به عنوان مدل از پیش‌آموزش‌دیده
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))
base_model.trainable = False  # فریز کردن لایه‌های از پیش آموزش‌دیده

# افزودن لایه‌های بالایی
model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dropout(0.5),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(len(CATEGORIES), activation='softmax')
])

# کامپایل مدل
optimizer = Adam(learning_rate=LEARNING_RATE)
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

# آموزش مدل
history = model.fit(train_generator, epochs=EPOCHS, validation_data=test_generator)

# باز کردن برخی لایه‌های انتهایی MobileNetV2
for layer in base_model.layers[-20:]:
    layer.trainable = True

# کامپایل مجدد مدل با نرخ یادگیری کمتر
model.compile(optimizer=Adam(learning_rate=LEARNING_RATE / 10), loss='categorical_crossentropy', metrics=['accuracy'])

# ادامه آموزش مدل
history_fine_tune = model.fit(train_generator, epochs=EPOCHS + 10, validation_data=test_generator)

# ارزیابی نهایی
test_loss, test_accuracy = model.evaluate(test_generator)
print(f"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}")

# گزارش عملکرد
y_pred = np.argmax(model.predict(X_test), axis=1)
y_true = np.argmax(y_test, axis=1)
print(classification_report(y_true, y_pred, target_names=CATEGORIES))

# نمایش ماتریس درهم‌ریختگی
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8, 6))
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
plt.xticks(np.arange(len(CATEGORIES)), CATEGORIES, rotation=45)
plt.yticks(np.arange(len(CATEGORIES)), CATEGORIES)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# رسم نمودار دقت و خطا
def plot_history(history):
    plt.figure(figsize=(12, 4))

    # دقت
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.title('Model Accuracy')

    # خطا
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.title('Model Loss')

    plt.show()

plot_history(history)
plot_history(history_fine_tune)

# -*- coding: utf-8 -*-
"""Driver Drowsiness Detection Final Project"""

import os
import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelBinarizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
import opendatasets as od

# Download Dataset from Kaggle
od.download("https://www.kaggle.com/datasets/dheerajperumandla/drowsiness-dataset")
od.download("https://www.kaggle.com/datasets/adinishad/prediction-images")

# Defining the Image Size and Categories
IMG_SIZE = 145
categories = ["yawn", "no_yawn", "Closed", "Open"]

# Haar Cascade for face detection
face_cascade = cv2.CascadeClassifier('./prediction-images/haarcascade_frontalface_default.xml')

def process_image(directory, categories, face_cascade):
    data = []
    for category in categories:
        path = os.path.join(directory, category)
        class_num = categories.index(category)
        for img in os.listdir(path):
            try:
                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)

                # Face detection with Haar Cascade
                faces = face_cascade.detectMultiScale(img_array, scaleFactor=1.3, minNeighbors=5)
                for (x, y, w, h) in faces:
                    roi_color = img_array[y:y + h, x:x + w]

                    # Resize to required dimensions
                    resized_image = cv2.resize(roi_color, (IMG_SIZE, IMG_SIZE))

                    # Normalize to 0-1 range
                    normalized_image = resized_image / 255.0

                    data.append([normalized_image, class_num])
            except Exception as e:
                print(f"Error processing image {img}: {e}")
    return data

# Processing images
data = process_image('./drowsiness-dataset/train', categories, face_cascade)

# Preparing features and labels
X = []
y = []
for feature, label in data:
    X.append(feature)
    y.append(label)

X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3)

# One-Hot Encoding of labels
label_bin = LabelBinarizer()
y = label_bin.fit_transform(y)
y = np.array(y)

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)

# Data Augmentation
train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.2, horizontal_flip=True, rotation_range=30)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow(X_train, y_train, shuffle=True)
test_generator = test_datagen.flow(X_test, y_test, shuffle=True)

# Building the CNN Model
model = Sequential()
model.add(Conv2D(64, (3, 3), activation="relu", input_shape=X_train.shape[1:]))
model.add(MaxPooling2D(2, 2))
model.add(Conv2D(128, (3, 3), activation="relu"))
model.add(MaxPooling2D(2, 2))
model.add(Flatten())
model.add(Dense(128, activation="relu"))
model.add(Dropout(0.5))
model.add(Dense(4, activation="softmax"))

# Compile Model
optimizer = Adam(learning_rate=0.0001)
model.compile(loss="categorical_crossentropy", metrics=["accuracy"], optimizer=optimizer)
model.summary()

# Training the Model
history = model.fit(train_generator, epochs=30, validation_data=test_generator)

# Save the model
model.save("drowsiness_model.h5")

# Evaluate the Model
test_loss, test_accuracy = model.evaluate(test_generator)
print(f'Test Loss: {test_loss}')
print(f'Test Accuracy: {test_accuracy}')

# Generate Predictions
predictions = model.predict(X_test)
predicted_classes = np.argmax(predictions, axis=1)

# Generate Classification Report
filtered_categories = [categories[i] for i in np.unique(np.argmax(y_test, axis=1))]
print(classification_report(np.argmax(y_test, axis=1), predicted_classes, target_names=filtered_categories))

# Generate Confusion Matrix
cm = confusion_matrix(np.argmax(y_test, axis=1), predicted_classes)
print("Confusion Matrix:\n", cm)

# Function to prepare and predict new images
def prepare(filepath):
    img_array = cv2.imread(filepath, cv2.IMREAD_COLOR)
    img_array = img_array / 255.0  # Normalize image
    resized_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))
    return resized_array.reshape(-1, IMG_SIZE, IMG_SIZE, 3)

def predict_image(image_path):
    prediction = model.predict(prepare(image_path))
    prediction_label = np.argmax(prediction)
    print(f"Prediction Label: {prediction_label}")
    print(f"Prediction: {categories[prediction_label]}")

# Example Usage: Predict on a random image
predict_image("./drowsiness-dataset/train/Closed/_34.jpg")

!pip install opendatasets